{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012314,
     "end_time": "2021-06-14T11:19:49.342358",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.330044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Generating Movie Recommendations\n",
    "\n",
    "### Unsupervised_Learning_ZM6\n",
    "\n",
    "1. Noxolo Ngcobo\n",
    "2. Mora Magakwe\n",
    "3. Sandra Malope\n",
    "4. Katleho Moketo\n",
    "5. Shuaib Morris\n",
    "6. Matthews Montle\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Recommendation systems are becoming increasingly important in todayâ€™s extremely busy world. People are forever short on time due to the tasks they need to accomplish in the limited time they have. Therefore, the recommendation systems are very important as they assist in making the right choices.\n",
    "\n",
    "The purpose of a recommendation system basically is to search for content that would be interesting to an individual. Moreover, it involves a number of factors to create personalised lists of useful and interesting content specific to each user/individual. Recommendation systems are Artificial Intelligence based algorithms that skim through all possible options and create a customized list of items that are interesting and relevant to an individual. These results are based on their profile, search/browsing history, what other people with similar traits/demographics are watching, and how likely are you to watch those movies. This is achieved through predictive modeling and heuristics with the data available.\n",
    "\n",
    "With this context, EDSA is challenging us to construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n",
    "\n",
    "Providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"center\" style=\"width: 900px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/kmoketo-dev/ZM6_Unsurpervised-Learning-Predict/main/intro.jpg\"\n",
    "     alt=\"Titanic\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=900px/>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.024972,
     "end_time": "2021-06-14T11:19:49.378659",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.353687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011326,
     "end_time": "2021-06-14T11:19:49.401974",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.390648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installing packages\n",
    "Please download all relevant packages in. There is no terminal so you will pip install everything.\n",
    "\n",
    "You can find a list of recommended install from the Intro to Recommender sysytem notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:32:07.674616Z",
     "iopub.status.busy": "2021-07-05T14:32:07.674255Z",
     "iopub.status.idle": "2021-07-05T14:32:08.706725Z",
     "shell.execute_reply": "2021-07-05T14:32:08.705906Z",
     "shell.execute_reply.started": "2021-07-05T14:32:07.674540Z"
    },
    "papermill": {
     "duration": 1.07453,
     "end_time": "2021-06-14T11:19:50.48799",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.41346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install packages here\n",
    "# Packages for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Packages for modeling\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "import heapq\n",
    "\n",
    "# Packages for model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from time import time\n",
    "\n",
    "# Package to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011369,
     "end_time": "2021-06-14T11:19:50.511223",
     "exception": false,
     "start_time": "2021-06-14T11:19:50.499854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:32:13.677559Z",
     "iopub.status.busy": "2021-07-05T14:32:13.677243Z",
     "iopub.status.idle": "2021-07-05T14:32:33.915533Z",
     "shell.execute_reply": "2021-07-05T14:32:33.914461Z",
     "shell.execute_reply.started": "2021-07-05T14:32:13.677530Z"
    },
    "papermill": {
     "duration": 17.847754,
     "end_time": "2021-06-14T11:20:08.371525",
     "exception": false,
     "start_time": "2021-06-14T11:19:50.523771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_sample_submission = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/sample_submission.csv')\n",
    "# df_movies = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/movies.csv')\n",
    "# df_imdb = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/imdb_data.csv')\n",
    "# df_genome_scores = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_scores.csv')\n",
    "# df_genome_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_tags.csv')\n",
    "# df_train = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/train.csv')\n",
    "# df_test = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/test.csv')\n",
    "# df_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/tags.csv')\n",
    "# df_links = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv('sample_submission.csv')\n",
    "df_movies = pd.read_csv('movies.csv')\n",
    "df_imdb = pd.read_csv('imdb_data.csv')\n",
    "df_genome_scores = pd.read_csv('genome_scores.csv')\n",
    "df_genome_tags = pd.read_csv('genome_tags.csv')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_tags = pd.read_csv('tags.csv')\n",
    "df_links = pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.037338,
     "end_time": "2021-06-14T11:20:08.420852",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.383514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genome_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genome_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(df_train,df_movies,on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011896,
     "end_time": "2021-06-14T11:20:08.480518",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.468622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EDA\n",
    "Discovery phase and data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average rating\n",
    "a=dataset\n",
    "a=a.groupby('title')['rating'].mean().head()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the rating of each movie\n",
    "b=dataset.groupby('title')['rating'].count()\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a new dataframe\n",
    "new_record = pd.DataFrame()\n",
    "new_record['Average_ratings']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_record['Count of total ratings'] = b\n",
    "new_record.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of num of \n",
    "plt.figure(figsize=(10,9))\n",
    "\n",
    "new_record['Count of total ratings'].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of ratings column\n",
    "plt.figure(figsize =(10,4))\n",
    "\n",
    "new_record['Average_ratings'].hist(bins = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.jointplot(x='Average_ratings',  y='Count of total ratings',data=new_record,alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df=pd.merge(df_train, df_movies,on='movieId',how='inner')\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genres with highest rating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_count=movies_df['genres'].value_counts().sort_values(ascending=False)\n",
    "genre_count=pd.DataFrame(genre_count)\n",
    "top_genre=genre_count[0:11]\n",
    "top_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the number of times a user rated a movie\n",
    "user_df = pd.DataFrame(\n",
    "    df_train['userId'].value_counts()).reset_index()\n",
    "user_df.rename(columns={'index':'userId','userId':'count'},\n",
    "                  inplace=True)\n",
    "user_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "data = df_train['userId'].value_counts().head(10)\n",
    "ax = sns.barplot(x = data.index, y = data, order= data.index, palette='CMRmap', edgecolor=\"black\")\n",
    "plt.title(f'Top 10 Users by Number of Ratings', fontsize=14)\n",
    "plt.xlabel('User ID')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that user the with id **72315** has the highest rating count of **12952**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRating_Group = df_train['rating'].value_counts().sort_index().reset_index()\n",
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "sns.barplot(data=movieRating_Group, x='index', y='rating', palette=\"CMRmap\", edgecolor=\"black\", ax=ax)\n",
    "ax.set_xlabel(\"Rating\")\n",
    "ax.set_ylabel('Number of Users')\n",
    "ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n",
    "total = float(movieRating_Group['rating'].sum())\n",
    "plt.title('Number of Users Per Rating', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011758,
     "end_time": "2021-06-14T11:20:08.504322",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.492564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Most common Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.255771,
     "end_time": "2021-06-14T11:20:08.772264",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.516493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dataframe containing only the movieId and genres\n",
    "movies_genres = pd.DataFrame(df_movies[['movieId', 'genres']],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\n",
    "movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n",
    "\n",
    "# Create expanded dataframe where each movie-genre combination is in a seperate row\n",
    "movies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "movies_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "papermill": {
     "duration": 0.347466,
     "end_time": "2021-06-14T11:20:09.132573",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.785107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the genres from most common to least common\n",
    "plot = plt.figure(figsize=(15, 10))\n",
    "plt.title('Most common genres\\n', fontsize=20)\n",
    "sns.countplot(y=\"genres\", data=movies_genres,\n",
    "              order=movies_genres['genres'].value_counts(ascending=False).index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for title in movies_df['title']:\n",
    "    if title[-1] == \" \":\n",
    "        year = title[-6: -2]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "    else:\n",
    "        year = title[-5: -1]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "\n",
    "movies_df['Year'] = dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Years in which movies were released**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(y=\"Year\", data=movies_df, palette=\"Set2\", order=movies_df['Year'].value_counts().index[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, **1995** was the year when most of the movies were released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('title')['rating'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame(dataset.groupby('title')['rating'].mean())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['num of ratings'] = pd.DataFrame(dataset.groupby('title')['rating'].count())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "ratings['num of ratings'].hist(bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "ratings['rating'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='rating',y='num of ratings',data=ratings,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for title in df_movies['title']:\n",
    "    yearpub_subset = title[-5:-1]\n",
    "    try: years.append(int(yearpub_subset))\n",
    "    except: years.append(9999)\n",
    "        \n",
    "df_movies['yearpub'] = years\n",
    "print(len(df_movies[df_movies['yearpub'] == 9999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_histogram(dataset, attribute, bins=25, bar_color='#3498db', edge_color='#2980b9', title='Title', xlab='X', ylab='Y', sort_index=False):\n",
    "    if attribute == 'yearpub':\n",
    "        dataset = dataset[dataset['yearpub'] != 9999]\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(title, fontsize=24, pad=20)\n",
    "    ax.set_xlabel(xlab, fontsize=16, labelpad=20)\n",
    "    ax.set_ylabel(ylab, fontsize=16, labelpad=20)\n",
    "    \n",
    "    plt.hist(dataset[attribute], bins=bins, color=bar_color, ec=edge_color, linewidth=2)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    \n",
    "make_histogram(df_movies, 'yearpub', title='Movies per year distribution', xlab='year', ylab='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.DataFrame()\n",
    "ratings_df['Mean_Rating'] = dataset.groupby('title')['rating'].mean().values\n",
    "ratings_df['Num_Ratings'] = dataset.groupby('title')['rating'].count().values\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_title('Rating vs. Number of Ratings', fontsize=24, pad=20)\n",
    "ax.set_xlabel('Rating', fontsize=16, labelpad=20)\n",
    "ax.set_ylabel('Number of Ratings', fontsize=16, labelpad=20)\n",
    "\n",
    "plt.scatter(ratings_df['Mean_Rating'], ratings_df['Num_Ratings'], alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012939,
     "end_time": "2021-06-14T11:20:09.159029",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.14609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T15:11:56.868263Z",
     "iopub.status.busy": "2021-07-05T15:11:56.867939Z",
     "iopub.status.idle": "2021-07-05T15:11:56.974830Z",
     "shell.execute_reply": "2021-07-05T15:11:56.973863Z",
     "shell.execute_reply.started": "2021-07-05T15:11:56.868234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    2652977\n",
       "3.0    1959759\n",
       "5.0    1445230\n",
       "3.5    1270642\n",
       "4.5     880516\n",
       "2.0     656821\n",
       "2.5     505578\n",
       "1.0     311213\n",
       "1.5     159731\n",
       "0.5     157571\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T15:21:29.538595Z",
     "iopub.status.busy": "2021-07-05T15:21:29.538265Z",
     "iopub.status.idle": "2021-07-05T15:21:31.736164Z",
     "shell.execute_reply": "2021-07-05T15:21:31.735149Z",
     "shell.execute_reply.started": "2021-07-05T15:21:29.538563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1551,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1177413"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_train['userId'].value_counts() > 500\n",
    "y = x[x].index  #user_ids\n",
    "print(y.shape)\n",
    "users = df_train[df_train['userId'].isin(y)]\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization-based Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:32:56.857604Z",
     "iopub.status.busy": "2021-07-05T14:32:56.857277Z",
     "iopub.status.idle": "2021-07-05T14:32:56.961104Z",
     "shell.execute_reply": "2021-07-05T14:32:56.960215Z",
     "shell.execute_reply.started": "2021-07-05T14:32:56.857573Z"
    }
   },
   "outputs": [],
   "source": [
    "#splitting data\n",
    "train_data=df_train.iloc[:int(df_train.shape[0]*0.80)]\n",
    "test_data=df_train.iloc[int(df_train.shape[0]*0.80):] \n",
    "train_data.drop(['timestamp'], 1, inplace = True)\n",
    "test_data.drop(['timestamp'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:33:02.472033Z",
     "iopub.status.busy": "2021-07-05T14:33:02.471666Z",
     "iopub.status.idle": "2021-07-05T14:33:02.479185Z",
     "shell.execute_reply": "2021-07-05T14:33:02.478212Z",
     "shell.execute_reply.started": "2021-07-05T14:33:02.472001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000030, 3), (2000008, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:33:05.521592Z",
     "iopub.status.busy": "2021-07-05T14:33:05.521236Z",
     "iopub.status.idle": "2021-07-05T14:33:29.209995Z",
     "shell.execute_reply": "2021-07-05T14:33:29.209112Z",
     "shell.execute_reply.started": "2021-07-05T14:33:05.521561Z"
    },
    "papermill": {
     "duration": 0.018806,
     "end_time": "2021-06-14T11:20:09.191326",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.17252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Here you will sort your data out and process it accordingly\n",
    "# This  specifies how to read the data frame.\n",
    "init_reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# create the traindata from the data frame\n",
    "train_data_mf = Dataset.load_from_df(train_data[['userId', 'movieId', 'rating']], init_reader)\n",
    "# build the train set from traindata. \n",
    "#It is of dataset format from surprise library\n",
    "trainset = train_data_mf.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:33:42.703777Z",
     "iopub.status.busy": "2021-07-05T14:33:42.703436Z",
     "iopub.status.idle": "2021-07-05T14:33:51.777762Z",
     "shell.execute_reply": "2021-07-05T14:33:51.776802Z",
     "shell.execute_reply.started": "2021-07-05T14:33:42.703746Z"
    }
   },
   "outputs": [],
   "source": [
    "init_reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# create the traindata from the data frame\n",
    "test_data_mf = Dataset.load_from_df(test_data[['userId', 'movieId', 'rating']], init_reader)\n",
    "# build the train set from traindata. \n",
    "#It is of dataset format from surprise library\n",
    "testset = test_data_mf.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:34:02.120210Z",
     "iopub.status.busy": "2021-07-05T14:34:02.119880Z",
     "iopub.status.idle": "2021-07-05T14:46:33.532287Z",
     "shell.execute_reply": "2021-07-05T14:46:33.531310Z",
     "shell.execute_reply.started": "2021-07-05T14:34:02.120180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f91c6a80390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(n_factors=100, biased=True, random_state=15, verbose=True)\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:49:33.464941Z",
     "iopub.status.busy": "2021-07-05T14:49:33.464595Z",
     "iopub.status.idle": "2021-07-05T14:51:34.799007Z",
     "shell.execute_reply": "2021-07-05T14:51:34.798114Z",
     "shell.execute_reply.started": "2021-07-05T14:49:33.464910Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting predictions of train set\n",
    "train_preds = svd.test(trainset.build_testset())\n",
    "train_pred_mf = np.array([pred.est for pred in train_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:51:40.475722Z",
     "iopub.status.busy": "2021-07-05T14:51:40.475347Z",
     "iopub.status.idle": "2021-07-05T14:52:08.178494Z",
     "shell.execute_reply": "2021-07-05T14:52:08.177626Z",
     "shell.execute_reply.started": "2021-07-05T14:51:40.475670Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting predictions of testset\n",
    "test_preds = svd.test(testset.build_testset())\n",
    "\n",
    "test_pred_mf = np.array([pred.est for pred in test_preds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013398,
     "end_time": "2021-06-14T11:20:09.218336",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.204938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modelling phase\n",
    "\n",
    "Here you can apply the models outline in the Intro to Recommender Notebook. You only need to apply one version \n",
    "be it Content based or Collabrative method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:52:22.095497Z",
     "iopub.status.busy": "2021-07-05T14:52:22.095186Z",
     "iopub.status.idle": "2021-07-05T14:52:22.646662Z",
     "shell.execute_reply": "2021-07-05T14:52:22.645801Z",
     "shell.execute_reply.started": "2021-07-05T14:52:22.095469Z"
    },
    "papermill": {
     "duration": 0.019188,
     "end_time": "2021-06-14T11:20:09.251198",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.23201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "train_sparse_matrix = csr_matrix((train_data.rating.values, (train_data.userId.values, train_data.movieId.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features which represent the global averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:52:30.035410Z",
     "iopub.status.busy": "2021-07-05T14:52:30.035092Z",
     "iopub.status.idle": "2021-07-05T14:52:30.081883Z",
     "shell.execute_reply": "2021-07-05T14:52:30.080901Z",
     "shell.execute_reply.started": "2021-07-05T14:52:30.035382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': 3.5334301246370328}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_averages = dict()\n",
    "# get the global average of ratings in our train set.\n",
    "train_global_average = train_sparse_matrix.sum()/train_sparse_matrix.count_nonzero()\n",
    "train_averages['global'] = train_global_average\n",
    "train_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:52:38.091395Z",
     "iopub.status.busy": "2021-07-05T14:52:38.091088Z",
     "iopub.status.idle": "2021-07-05T14:52:38.096986Z",
     "shell.execute_reply": "2021-07-05T14:52:38.096062Z",
     "shell.execute_reply.started": "2021-07-05T14:52:38.091368Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_average_ratings(sparse_matrix, of_users):\n",
    "    \n",
    "    # average ratings of user/axes\n",
    "    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n",
    "\n",
    "    # \".A1\" is for converting Column_Matrix to 1-D numpy array \n",
    "    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n",
    "    # Boolean matrix of ratings ( whether a user rated that movie or not)\n",
    "    is_rated = sparse_matrix!=0\n",
    "    # no of ratings that each user OR movie..\n",
    "    no_of_ratings = is_rated.sum(axis=ax).A1\n",
    "    \n",
    "    # max_user  and max_movie ids in sparse matrix \n",
    "    u,m = sparse_matrix.shape\n",
    "    # creae a dictonary of users and their average ratigns..\n",
    "    average_ratings = { i : sum_of_ratings[i]/no_of_ratings[i]\n",
    "                                 for i in range(u if of_users else m) \n",
    "                                    if no_of_ratings[i] !=0}\n",
    "\n",
    "    # return that dictionary of average ratings\n",
    "    return average_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:52:44.965662Z",
     "iopub.status.busy": "2021-07-05T14:52:44.965345Z",
     "iopub.status.idle": "2021-07-05T14:52:45.248622Z",
     "shell.execute_reply": "2021-07-05T14:52:45.247640Z",
     "shell.execute_reply.started": "2021-07-05T14:52:44.965633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average rating of user 10 : 3.75\n"
     ]
    }
   ],
   "source": [
    "# Average ratings given by a user\n",
    "train_averages['user'] = get_average_ratings(train_sparse_matrix, of_users=True)\n",
    "print('\\nAverage rating of user 10 :',train_averages['user'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:52:48.785349Z",
     "iopub.status.busy": "2021-07-05T14:52:48.785022Z",
     "iopub.status.idle": "2021-07-05T14:52:49.020924Z",
     "shell.execute_reply": "2021-07-05T14:52:49.020012Z",
     "shell.execute_reply.started": "2021-07-05T14:52:48.785320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " AVerage rating of movie 15 : 2.728359908883827\n"
     ]
    }
   ],
   "source": [
    "# Average ratings given for a movie\n",
    "train_averages['movie'] =  get_average_ratings(train_sparse_matrix, of_users=False)\n",
    "print('\\n AVerage rating of movie 15 :',train_averages['movie'][15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:52:53.662897Z",
     "iopub.status.busy": "2021-07-05T14:52:53.662496Z",
     "iopub.status.idle": "2021-07-05T14:52:54.859402Z",
     "shell.execute_reply": "2021-07-05T14:52:54.858543Z",
     "shell.execute_reply.started": "2021-07-05T14:52:53.662862Z"
    }
   },
   "outputs": [],
   "source": [
    "# get users, movies and ratings from our samples train sparse matrix\n",
    "from scipy.sparse import find\n",
    "train_users, train_movies, train_ratings = find(train_sparse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features which represent the top 5 similar users and 5 top similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:53:02.609900Z",
     "iopub.status.busy": "2021-07-05T14:53:02.609552Z",
     "iopub.status.idle": "2021-07-05T14:53:02.620034Z",
     "shell.execute_reply": "2021-07-05T14:53:02.619177Z",
     "shell.execute_reply.started": "2021-07-05T14:53:02.609871Z"
    }
   },
   "outputs": [],
   "source": [
    "def ratings_(train_users, train_movies, train_ratings):\n",
    "    final_data = pd.DataFrame()\n",
    "    for (user, movie, rating)  in zip(train_users, train_movies, train_ratings):\n",
    "\n",
    "            #     print(user, movie)    \n",
    "                #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n",
    "                # compute the similar Users of the \"user\"        \n",
    "        user_sim = cosine_similarity(train_sparse_matrix[user], train_sparse_matrix).ravel()\n",
    "        top_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n",
    "                # get the ratings of most similar users for this movie\n",
    "        top_ratings = train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "                # we will make it's length \"5\" by adding movie averages to .\n",
    "        top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "        top_sim_users_ratings.extend([train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "            #     print(top_sim_users_ratings, end=\" \")    \n",
    "\n",
    "\n",
    "                #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n",
    "                # compute the similar movies of the \"movie\"        \n",
    "        movie_sim = cosine_similarity(train_sparse_matrix[:,movie].T, train_sparse_matrix.T).ravel()\n",
    "        top_sim_movies = movie_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n",
    "                # get the ratings of most similar movie rated by this user..\n",
    "        top_ratings = train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "                # we will make it's length \"5\" by adding user averages to.\n",
    "        top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "        top_sim_movies_ratings.extend([train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n",
    "            #     print(top_sim_movies_ratings, end=\" : -- \")\n",
    "\n",
    "                #-----------------prepare the row to be stores in a file-----------------#\n",
    "        row = list()\n",
    "        row.append(user)\n",
    "        row.append(movie)\n",
    "                # Now add the other features to this data...\n",
    "        row.append(train_averages['global']) # first feature\n",
    "                # next 5 features are similar_users \"movie\" ratings\n",
    "        row.extend(top_sim_users_ratings)\n",
    "                # next 5 features are \"user\" ratings for similar_movies\n",
    "        row.extend(top_sim_movies_ratings)\n",
    "                # Avg_user rating\n",
    "        row.append(train_averages['user'][user])\n",
    "                # Avg_movie rating\n",
    "        row.append(train_averages['movie'][movie])\n",
    "\n",
    "                # finalley, The actual Rating of this user-movie pair...\n",
    "        row.append(rating)\n",
    "        #count = count + 1\n",
    "        final_data = final_data.append([row])\n",
    "            \n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:53:09.552129Z",
     "iopub.status.busy": "2021-07-05T14:53:09.551773Z",
     "iopub.status.idle": "2021-07-05T15:08:28.554511Z",
     "shell.execute_reply": "2021-07-05T15:08:28.552086Z",
     "shell.execute_reply.started": "2021-07-05T14:53:09.552095Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-aed0ab229461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_movies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-ec62b25aeccb>\u001b[0m in \u001b[0;36mratings_\u001b[0;34m(train_users, train_movies, train_ratings)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m#--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# compute the similar movies of the \"movie\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmovie_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sparse_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmovie\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sparse_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtop_sim_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# we are ignoring 'The User' from its similar users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# get the ratings of most similar movie rated by this user..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    149\u001b[0m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[1;32m    150\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                         estimator=estimator)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprecomputed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    594\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[1;32m    597\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;31m# create new with correct sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mspmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mchanged_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;31m# Forward the copy kwarg, if it's accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/sparse/csc.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m                   \u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                   \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                   data)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_train = ratings_(train_users, train_movies, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013848,
     "end_time": "2021-06-14T11:20:09.278819",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.264971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate your outputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013303,
     "end_time": "2021-06-14T11:20:09.305786",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.292483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prepare Submission File\n",
    "We make submissions in CSV files. Your submissions usually have two columns: an ID column and a prediction column. The ID field comes from the test data (keeping whatever name the ID field had in that data, which for the data is the string 'Id'). The prediction column will use the name of the target field.\n",
    "\n",
    "We will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.019235,
     "end_time": "2021-06-14T11:20:09.338682",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.319447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is an example\n",
    "## my_submission = pd.DataFrame({'id': test.Id, 'rating': test.ratings})\n",
    "# you could use any filename. We choose submission here\n",
    "## my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013706,
     "end_time": "2021-06-14T11:20:09.365804",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.352098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Make Submission\n",
    "Hit the blue Publish button at the top of your notebook screen. It will take some time for your kernel to run. When it has finished your navigation bar at the top of the screen will have a tab for Output. This only shows up if you have written an output file (like we did in the Prepare Submission File step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01348,
     "end_time": "2021-06-14T11:20:09.393074",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.379594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Example below of how the output would look once published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026311,
     "end_time": "2021-06-14T11:20:09.433177",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.406866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize list of lists\n",
    "data = [['tom', 10], ['nick', 15], ['juli', 14]]\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(data, columns = ['Name', 'Age'])\n",
    "  \n",
    "# print dataframe.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.023908,
     "end_time": "2021-06-14T11:20:09.470967",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.447059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('my_test_output.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.013439,
     "end_time": "2021-06-14T11:20:09.498408",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.484969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
