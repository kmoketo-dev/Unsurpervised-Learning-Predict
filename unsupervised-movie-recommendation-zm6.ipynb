{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012314,
     "end_time": "2021-06-14T11:19:49.342358",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.330044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Generating Movie Recommendations\n",
    "\n",
    "### Unsupervised_Learning_ZM6\n",
    "\n",
    "1. Noxolo Ngcobo\n",
    "2. Mora Magakwe\n",
    "3. Sandra Malope\n",
    "4. Katleho Moketo\n",
    "5. Shuaib Morris\n",
    "6. Matthews Montle\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Recommendation systems are becoming increasingly important in todayâ€™s extremely busy world. People are forever short on time due to the tasks they need to accomplish in the limited time they have. Therefore, the recommendation systems are very important as they assist in making the right choices.\n",
    "\n",
    "The purpose of a recommendation system basically is to search for content that would be interesting to an individual. Moreover, it involves a number of factors to create personalised lists of useful and interesting content specific to each user/individual. Recommendation systems are Artificial Intelligence based algorithms that skim through all possible options and create a customized list of items that are interesting and relevant to an individual. These results are based on their profile, search/browsing history, what other people with similar traits/demographics are watching, and how likely are you to watch those movies. This is achieved through predictive modeling and heuristics with the data available.\n",
    "\n",
    "With this context, EDSA is challenging us to construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n",
    "\n",
    "Providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"center\" style=\"width: 900px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/kmoketo-dev/ZM6_Unsurpervised-Learning-Predict/main/intro.jpg\"\n",
    "     alt=\"Titanic\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=900px/>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.024972,
     "end_time": "2021-06-14T11:19:49.378659",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.353687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011326,
     "end_time": "2021-06-14T11:19:49.401974",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.390648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installing packages\n",
    "Please download all relevant packages in. There is no terminal so you will pip install everything.\n",
    "\n",
    "You can find a list of recommended install from the Intro to Recommender sysytem notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:32:07.674616Z",
     "iopub.status.busy": "2021-07-05T14:32:07.674255Z",
     "iopub.status.idle": "2021-07-05T14:32:08.706725Z",
     "shell.execute_reply": "2021-07-05T14:32:08.705906Z",
     "shell.execute_reply.started": "2021-07-05T14:32:07.674540Z"
    },
    "papermill": {
     "duration": 1.07453,
     "end_time": "2021-06-14T11:19:50.48799",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.41346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install packages here\n",
    "# Packages for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Packages for modeling\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "import heapq\n",
    "\n",
    "# Packages for model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from time import time\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from surprise.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "\n",
    "# Package to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011369,
     "end_time": "2021-06-14T11:19:50.511223",
     "exception": false,
     "start_time": "2021-06-14T11:19:50.499854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:32:13.677559Z",
     "iopub.status.busy": "2021-07-05T14:32:13.677243Z",
     "iopub.status.idle": "2021-07-05T14:32:33.915533Z",
     "shell.execute_reply": "2021-07-05T14:32:33.914461Z",
     "shell.execute_reply.started": "2021-07-05T14:32:13.677530Z"
    },
    "papermill": {
     "duration": 17.847754,
     "end_time": "2021-06-14T11:20:08.371525",
     "exception": false,
     "start_time": "2021-06-14T11:19:50.523771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_sample_submission = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/sample_submission.csv')\n",
    "# df_movies = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/movies.csv')\n",
    "# df_imdb = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/imdb_data.csv')\n",
    "# df_genome_scores = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_scores.csv')\n",
    "# df_genome_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_tags.csv')\n",
    "# df_train = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/train.csv')\n",
    "# df_test = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/test.csv')\n",
    "# df_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/tags.csv')\n",
    "# df_links = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv('sample_submission.csv')\n",
    "df_movies = pd.read_csv('movies.csv')\n",
    "df_imdb = pd.read_csv('imdb_data.csv')\n",
    "df_genome_scores = pd.read_csv('genome_scores.csv')\n",
    "df_genome_tags = pd.read_csv('genome_tags.csv')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_tags = pd.read_csv('tags.csv')\n",
    "df_links = pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.037338,
     "end_time": "2021-06-14T11:20:08.420852",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.383514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genome_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genome_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(df_train,df_movies,on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011896,
     "end_time": "2021-06-14T11:20:08.480518",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.468622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EDA\n",
    "Discovery phase and data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average rating\n",
    "a=dataset\n",
    "a=a.groupby('title')['rating'].mean().head()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the rating of each movie\n",
    "b=dataset.groupby('title')['rating'].count()\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a new dataframe\n",
    "new_record = pd.DataFrame()\n",
    "new_record['Average_ratings']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_record['Count of total ratings'] = b\n",
    "new_record.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of num of \n",
    "plt.figure(figsize=(10,9))\n",
    "\n",
    "new_record['Count of total ratings'].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of ratings column\n",
    "plt.figure(figsize =(10,4))\n",
    "\n",
    "new_record['Average_ratings'].hist(bins = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.jointplot(x='Average_ratings',  y='Count of total ratings',data=new_record,alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df=pd.merge(df_train, df_movies,on='movieId',how='inner')\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genres with highest rating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_count=movies_df['genres'].value_counts().sort_values(ascending=False)\n",
    "genre_count=pd.DataFrame(genre_count)\n",
    "top_genre=genre_count[0:11]\n",
    "top_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the number of times a user rated a movie\n",
    "user_df = pd.DataFrame(\n",
    "    df_train['userId'].value_counts()).reset_index()\n",
    "user_df.rename(columns={'index':'userId','userId':'count'},\n",
    "                  inplace=True)\n",
    "user_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "data = df_train['userId'].value_counts().head(10)\n",
    "ax = sns.barplot(x = data.index, y = data, order= data.index, palette='CMRmap', edgecolor=\"black\")\n",
    "plt.title(f'Top 10 Users by Number of Ratings', fontsize=14)\n",
    "plt.xlabel('User ID')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that user the with id **72315** has the highest rating count of **12952**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRating_Group = df_train['rating'].value_counts().sort_index().reset_index()\n",
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "sns.barplot(data=movieRating_Group, x='index', y='rating', palette=\"CMRmap\", edgecolor=\"black\", ax=ax)\n",
    "ax.set_xlabel(\"Rating\")\n",
    "ax.set_ylabel('Number of Users')\n",
    "ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n",
    "total = float(movieRating_Group['rating'].sum())\n",
    "plt.title('Number of Users Per Rating', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011758,
     "end_time": "2021-06-14T11:20:08.504322",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.492564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Most common Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.255771,
     "end_time": "2021-06-14T11:20:08.772264",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.516493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dataframe containing only the movieId and genres\n",
    "movies_genres = pd.DataFrame(df_movies[['movieId', 'genres']],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\n",
    "movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n",
    "\n",
    "# Create expanded dataframe where each movie-genre combination is in a seperate row\n",
    "movies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "movies_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "papermill": {
     "duration": 0.347466,
     "end_time": "2021-06-14T11:20:09.132573",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.785107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the genres from most common to least common\n",
    "plot = plt.figure(figsize=(15, 10))\n",
    "plt.title('Most common genres\\n', fontsize=20)\n",
    "sns.countplot(y=\"genres\", data=movies_genres,\n",
    "              order=movies_genres['genres'].value_counts(ascending=False).index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for title in movies_df['title']:\n",
    "    if title[-1] == \" \":\n",
    "        year = title[-6: -2]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "    else:\n",
    "        year = title[-5: -1]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "\n",
    "movies_df['Year'] = dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Years in which movies were released**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(y=\"Year\", data=movies_df, palette=\"Set2\", order=movies_df['Year'].value_counts().index[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, **1995** was the year when most of the movies were released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('title')['rating'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame(dataset.groupby('title')['rating'].mean())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['num of ratings'] = pd.DataFrame(dataset.groupby('title')['rating'].count())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "ratings['num of ratings'].hist(bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "ratings['rating'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='rating',y='num of ratings',data=ratings,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for title in df_movies['title']:\n",
    "    yearpub_subset = title[-5:-1]\n",
    "    try: years.append(int(yearpub_subset))\n",
    "    except: years.append(9999)\n",
    "        \n",
    "df_movies['yearpub'] = years\n",
    "print(len(df_movies[df_movies['yearpub'] == 9999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_histogram(dataset, attribute, bins=25, bar_color='#3498db', edge_color='#2980b9', title='Title', xlab='X', ylab='Y', sort_index=False):\n",
    "    if attribute == 'yearpub':\n",
    "        dataset = dataset[dataset['yearpub'] != 9999]\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(title, fontsize=24, pad=20)\n",
    "    ax.set_xlabel(xlab, fontsize=16, labelpad=20)\n",
    "    ax.set_ylabel(ylab, fontsize=16, labelpad=20)\n",
    "    \n",
    "    plt.hist(dataset[attribute], bins=bins, color=bar_color, ec=edge_color, linewidth=2)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    \n",
    "make_histogram(df_movies, 'yearpub', title='Movies per year distribution', xlab='year', ylab='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.DataFrame()\n",
    "ratings_df['Mean_Rating'] = dataset.groupby('title')['rating'].mean().values\n",
    "ratings_df['Num_Ratings'] = dataset.groupby('title')['rating'].count().values\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_title('Rating vs. Number of Ratings', fontsize=24, pad=20)\n",
    "ax.set_xlabel('Rating', fontsize=16, labelpad=20)\n",
    "ax.set_ylabel('Number of Ratings', fontsize=16, labelpad=20)\n",
    "\n",
    "plt.scatter(ratings_df['Mean_Rating'], ratings_df['Num_Ratings'], alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012939,
     "end_time": "2021-06-14T11:20:09.159029",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.14609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T15:11:56.868263Z",
     "iopub.status.busy": "2021-07-05T15:11:56.867939Z",
     "iopub.status.idle": "2021-07-05T15:11:56.974830Z",
     "shell.execute_reply": "2021-07-05T15:11:56.973863Z",
     "shell.execute_reply.started": "2021-07-05T15:11:56.868234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    2652977\n",
       "3.0    1959759\n",
       "5.0    1445230\n",
       "3.5    1270642\n",
       "4.5     880516\n",
       "2.0     656821\n",
       "2.5     505578\n",
       "1.0     311213\n",
       "1.5     159731\n",
       "0.5     157571\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T15:21:29.538595Z",
     "iopub.status.busy": "2021-07-05T15:21:29.538265Z",
     "iopub.status.idle": "2021-07-05T15:21:31.736164Z",
     "shell.execute_reply": "2021-07-05T15:21:31.735149Z",
     "shell.execute_reply.started": "2021-07-05T15:21:29.538563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1551,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_train['userId'].value_counts() > 500\n",
    "y = x[x].index  #user_ids\n",
    "print(y.shape)\n",
    "users = df_train.sample(n = 500000, replace = False)\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization-based Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:32:56.857604Z",
     "iopub.status.busy": "2021-07-05T14:32:56.857277Z",
     "iopub.status.idle": "2021-07-05T14:32:56.961104Z",
     "shell.execute_reply": "2021-07-05T14:32:56.960215Z",
     "shell.execute_reply.started": "2021-07-05T14:32:56.857573Z"
    }
   },
   "outputs": [],
   "source": [
    "#splitting data\n",
    "train_data=users.iloc[:int(users.shape[0]*0.80)]\n",
    "test_data=users.iloc[int(users.shape[0]*0.80):] \n",
    "train_data.drop(['timestamp'], 1, inplace = True)\n",
    "test_data.drop(['timestamp'], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:33:02.472033Z",
     "iopub.status.busy": "2021-07-05T14:33:02.471666Z",
     "iopub.status.idle": "2021-07-05T14:33:02.479185Z",
     "shell.execute_reply": "2021-07-05T14:33:02.478212Z",
     "shell.execute_reply.started": "2021-07-05T14:33:02.472001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400000, 3), (100000, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:33:05.521592Z",
     "iopub.status.busy": "2021-07-05T14:33:05.521236Z",
     "iopub.status.idle": "2021-07-05T14:33:29.209995Z",
     "shell.execute_reply": "2021-07-05T14:33:29.209112Z",
     "shell.execute_reply.started": "2021-07-05T14:33:05.521561Z"
    },
    "papermill": {
     "duration": 0.018806,
     "end_time": "2021-06-14T11:20:09.191326",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.17252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Here you will sort your data out and process it accordingly\n",
    "# This  specifies how to read the data frame.\n",
    "init_reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# create the traindata from the data frame\n",
    "train_data_mf = Dataset.load_from_df(train_data[['userId', 'movieId', 'rating']], init_reader)\n",
    "# build the train set from traindata. \n",
    "#It is of dataset format from surprise library\n",
    "trainset = train_data_mf.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:33:42.703777Z",
     "iopub.status.busy": "2021-07-05T14:33:42.703436Z",
     "iopub.status.idle": "2021-07-05T14:33:51.777762Z",
     "shell.execute_reply": "2021-07-05T14:33:51.776802Z",
     "shell.execute_reply.started": "2021-07-05T14:33:42.703746Z"
    }
   },
   "outputs": [],
   "source": [
    "init_reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# create the traindata from the data frame\n",
    "test_data_mf = Dataset.load_from_df(test_data[['userId', 'movieId', 'rating']], init_reader)\n",
    "# build the train set from traindata. \n",
    "#It is of dataset format from surprise library\n",
    "testset = test_data_mf.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:34:02.120210Z",
     "iopub.status.busy": "2021-07-05T14:34:02.119880Z",
     "iopub.status.idle": "2021-07-05T14:46:33.532287Z",
     "shell.execute_reply": "2021-07-05T14:46:33.531310Z",
     "shell.execute_reply.started": "2021-07-05T14:34:02.120180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1f7115119a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(n_factors=100, biased=True, random_state=15, verbose=True)\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013398,
     "end_time": "2021-06-14T11:20:09.218336",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.204938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modelling phase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:49:33.464941Z",
     "iopub.status.busy": "2021-07-05T14:49:33.464595Z",
     "iopub.status.idle": "2021-07-05T14:51:34.799007Z",
     "shell.execute_reply": "2021-07-05T14:51:34.798114Z",
     "shell.execute_reply.started": "2021-07-05T14:49:33.464910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.52607122, 3.18873575, 4.0609979 , ..., 3.9800159 , 3.46368535,\n",
       "       3.78495266])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting predictions of train set\n",
    "train_preds = svd.test(trainset.build_testset())\n",
    "train_pred_mf = np.array([pred.est for pred in train_preds])\n",
    "train_pred_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:51:40.475722Z",
     "iopub.status.busy": "2021-07-05T14:51:40.475347Z",
     "iopub.status.idle": "2021-07-05T14:52:08.178494Z",
     "shell.execute_reply": "2021-07-05T14:52:08.177626Z",
     "shell.execute_reply.started": "2021-07-05T14:51:40.475670Z"
    }
   },
   "outputs": [],
   "source": [
    "#getting predictions of testset\n",
    "test_preds = svd.test(testset.build_testset())\n",
    "\n",
    "test_pred_mf = np.array([pred.est for pred in test_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6634204747061473"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE for trainset\n",
    "algo_rmse = accuracy.rmse(train_preds)\n",
    "algo_rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9298961867438427"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE for testset\n",
    "algo_rmse1 = accuracy.rmse(test_preds)\n",
    "algo_rmse1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101928</td>\n",
       "      <td>186</td>\n",
       "      <td>2.526071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101928</td>\n",
       "      <td>1544</td>\n",
       "      <td>3.188736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112631</td>\n",
       "      <td>4963</td>\n",
       "      <td>4.060998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112631</td>\n",
       "      <td>31685</td>\n",
       "      <td>2.910308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29367</td>\n",
       "      <td>2881</td>\n",
       "      <td>3.137705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId    rating\n",
       "0  101928      186  2.526071\n",
       "1  101928     1544  3.188736\n",
       "2  112631     4963  4.060998\n",
       "3  112631    31685  2.910308\n",
       "4   29367     2881  3.137705"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.DataFrame(train_preds)\n",
    "pred=pred.rename(columns={'uid':'userId', 'iid':'movieId','est':'rating'})\n",
    "pred.drop(['r_ui','details'],axis=1,inplace=True)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98334</td>\n",
       "      <td>112290</td>\n",
       "      <td>4.418536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98334</td>\n",
       "      <td>78349</td>\n",
       "      <td>3.802737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98334</td>\n",
       "      <td>924</td>\n",
       "      <td>4.780714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98334</td>\n",
       "      <td>3535</td>\n",
       "      <td>4.371402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98334</td>\n",
       "      <td>201646</td>\n",
       "      <td>4.261875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId    rating\n",
       "0   98334   112290  4.418536\n",
       "1   98334    78349  3.802737\n",
       "2   98334      924  4.780714\n",
       "3   98334     3535  4.371402\n",
       "4   98334   201646  4.261875"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = pd.DataFrame(test_preds)\n",
    "pred1=pred1.rename(columns={'uid':'userId', 'iid':'movieId','est':'rating'})\n",
    "pred1.drop(['r_ui','details'],axis=1,inplace=True)\n",
    "pred1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Trainset' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-34936664672a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msvdpp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVDpp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_factors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minit_std_dev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvdpp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msvdpp_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvdpp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msvdpp_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvdpp_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msvdpp_rmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, testset, verbose)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;31m# The ratings are translated back to their original scale.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         predictions = [self.predict(uid,\n\u001b[0m\u001b[0;32m    165\u001b[0m                                     \u001b[0miid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                                     \u001b[0mr_ui_trans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Trainset' object is not iterable"
     ]
    }
   ],
   "source": [
    "svdpp_model = SVDpp(n_epochs=20,n_factors=400,init_std_dev=0.001,random_state=42, verbose=True)\n",
    "svdpp_model.fit(trainset)\n",
    "svdpp_predictions = svdpp_model.test(testset)\n",
    "svdpp_rmse = accuracy.rmse(svdpp_predictions)\n",
    "svdpp_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9270729006710832"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_scale = Reader(rating_scale=(0.5, 5))\n",
    "#train_df = Dataset.load_from_df(train.drop('timestamp', axis=1), rating_scale)\n",
    "train_df = Dataset.load_from_df(users[['userId', 'movieId', 'rating']], rating_scale)\n",
    "\n",
    "# Training and validation set split for hypertuning\n",
    "trainset, testset = train_test_split(train_df,\n",
    "                                      test_size=0.008,\n",
    "                                      random_state=42)\n",
    "\n",
    "# Modelling of the SVD hypertuning\n",
    "svd_algo_hyper = SVD(n_factors=400, \n",
    "                     lr_all=0.0085,\n",
    "                     reg_all=0.02,\n",
    "                     n_epochs=40,\n",
    "                     init_std_dev=0.01,\n",
    "                     random_state=42)\n",
    "svd_algo_hyper.fit(trainset)\n",
    "\n",
    "# Predicting on the validation set\n",
    "svd_hyper_predictions = svd_algo_hyper.test(testset)\n",
    "\n",
    "acc = accuracy.rmse(svd_hyper_predictions)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013848,
     "end_time": "2021-06-14T11:20:09.278819",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.264971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate your outputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013303,
     "end_time": "2021-06-14T11:20:09.305786",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.292483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prepare Submission File\n",
    "We make submissions in CSV files. Your submissions usually have two columns: an ID column and a prediction column. The ID field comes from the test data (keeping whatever name the ID field had in that data, which for the data is the string 'Id'). The prediction column will use the name of the target field.\n",
    "\n",
    "We will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "papermill": {
     "duration": 0.019235,
     "end_time": "2021-06-14T11:20:09.338682",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.319447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_svd_hyper = [svd_algo_hyper.predict(row.userId,\n",
    "                                         row.movieId) for idx,row in df_test.iterrows()]\n",
    "\n",
    "# Converting the predictions to a dataframe\n",
    "test_pred_svd_hyper = pd.DataFrame(pred_svd_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013706,
     "end_time": "2021-06-14T11:20:09.365804",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.352098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Make Submission\n",
    "Hit the blue Publish button at the top of your notebook screen. It will take some time for your kernel to run. When it has finished your navigation bar at the top of the screen will have a tab for Output. This only shows up if you have written an output file (like we did in the Prepare Submission File step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01348,
     "end_time": "2021-06-14T11:20:09.393074",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.379594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Example below of how the output would look once published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "papermill": {
     "duration": 0.026311,
     "end_time": "2021-06-14T11:20:09.433177",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.406866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.446653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4144</td>\n",
       "      <td>4.065873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5767</td>\n",
       "      <td>3.452344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6711</td>\n",
       "      <td>3.745167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7318</td>\n",
       "      <td>3.138454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId    rating\n",
       "0       1     2011  3.446653\n",
       "1       1     4144  4.065873\n",
       "2       1     5767  3.452344\n",
       "3       1     6711  3.745167\n",
       "4       1     7318  3.138454"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the fields in the prediction dataframe\n",
    "test_pred_svd_hyper.drop(['r_ui', 'details'], axis=1, inplace=True)\n",
    "test_pred_svd_hyper = test_pred_svd_hyper.rename(columns={'uid':'userId',\n",
    "                                                          'iid':'movieId',\n",
    "                                                          'est':'rating'})\n",
    "test_pred_svd_hyper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "papermill": {
     "duration": 0.023908,
     "end_time": "2021-06-14T11:20:09.470967",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.447059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate each userId and movieId into a single Id column for submission\n",
    "test_pred_svd_hyper['Id'] =  test_pred_svd_hyper['userId'].astype(str).str.zfill(1) + '_' + test_pred_svd_hyper['movieId'].astype(str).str.zfill(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_2011</td>\n",
       "      <td>3.446653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_4144</td>\n",
       "      <td>4.065873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_5767</td>\n",
       "      <td>3.452344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_6711</td>\n",
       "      <td>3.745167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_7318</td>\n",
       "      <td>3.138454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id    rating\n",
       "0  1_2011  3.446653\n",
       "1  1_4144  4.065873\n",
       "2  1_5767  3.452344\n",
       "3  1_6711  3.745167\n",
       "4  1_7318  3.138454"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_hyper_predictions = test_pred_svd_hyper[['Id','rating']]\n",
    "svd_hyper_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "papermill": {
     "duration": 0.013439,
     "end_time": "2021-06-14T11:20:09.498408",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.484969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_hyper_predictions.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
