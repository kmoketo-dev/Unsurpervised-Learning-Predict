{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012314,
     "end_time": "2021-06-14T11:19:49.342358",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.330044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Generating Movie Recommendations\n",
    "\n",
    "### Unsupervised_Learning_ZM6\n",
    "\n",
    "1. Noxolo Ngcobo\n",
    "2. Mora Magakwe\n",
    "3. Sandra Malope\n",
    "4. Katleho Moketo\n",
    "5. Shuaib Morris\n",
    "6. Matthews Montle\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Recommendation systems are becoming increasingly important in todayâ€™s extremely busy world. People are forever short on time due to the tasks they need to accomplish in the limited time they have. Therefore, the recommendation systems are very important as they assist in making the right choices.\n",
    "\n",
    "The purpose of a recommendation system basically is to search for content that would be interesting to an individual. Moreover, it involves a number of factors to create personalised lists of useful and interesting content specific to each user/individual. Recommendation systems are Artificial Intelligence based algorithms that skim through all possible options and create a customized list of items that are interesting and relevant to an individual. These results are based on their profile, search/browsing history, what other people with similar traits/demographics are watching, and how likely are you to watch those movies. This is achieved through predictive modeling and heuristics with the data available.\n",
    "\n",
    "With this context, EDSA is challenging us to construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n",
    "\n",
    "Providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"center\" style=\"width: 900px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/kmoketo-dev/ZM6_Unsurpervised-Learning-Predict/main/intro.jpg\"\n",
    "     alt=\"Titanic\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=900px/>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.024972,
     "end_time": "2021-06-14T11:19:49.378659",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.353687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011326,
     "end_time": "2021-06-14T11:19:49.401974",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.390648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installing packages\n",
    "Please download all relevant packages in. There is no terminal so you will pip install everything.\n",
    "\n",
    "You can find a list of recommended install from the Intro to Recommender sysytem notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:32:07.674616Z",
     "iopub.status.busy": "2021-07-05T14:32:07.674255Z",
     "iopub.status.idle": "2021-07-05T14:32:08.706725Z",
     "shell.execute_reply": "2021-07-05T14:32:08.705906Z",
     "shell.execute_reply.started": "2021-07-05T14:32:07.674540Z"
    },
    "papermill": {
     "duration": 1.07453,
     "end_time": "2021-06-14T11:19:50.48799",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.41346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install packages here\n",
    "# Packages for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Packages for modeling\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "import heapq\n",
    "\n",
    "# Packages for model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from time import time\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from surprise.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "\n",
    "# Package to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011369,
     "end_time": "2021-06-14T11:19:50.511223",
     "exception": false,
     "start_time": "2021-06-14T11:19:50.499854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T14:32:13.677559Z",
     "iopub.status.busy": "2021-07-05T14:32:13.677243Z",
     "iopub.status.idle": "2021-07-05T14:32:33.915533Z",
     "shell.execute_reply": "2021-07-05T14:32:33.914461Z",
     "shell.execute_reply.started": "2021-07-05T14:32:13.677530Z"
    },
    "papermill": {
     "duration": 17.847754,
     "end_time": "2021-06-14T11:20:08.371525",
     "exception": false,
     "start_time": "2021-06-14T11:19:50.523771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_sample_submission = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/sample_submission.csv')\n",
    "# df_movies = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/movies.csv')\n",
    "# df_imdb = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/imdb_data.csv')\n",
    "# df_genome_scores = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_scores.csv')\n",
    "# df_genome_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_tags.csv')\n",
    "# df_train = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/train.csv')\n",
    "# df_test = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/test.csv')\n",
    "# df_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/tags.csv')\n",
    "# df_links = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv('sample_submission.csv')\n",
    "df_movies = pd.read_csv('movies.csv')\n",
    "df_imdb = pd.read_csv('imdb_data.csv')\n",
    "df_genome_scores = pd.read_csv('genome_scores.csv')\n",
    "df_genome_tags = pd.read_csv('genome_tags.csv')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_tags = pd.read_csv('tags.csv')\n",
    "df_links = pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.037338,
     "end_time": "2021-06-14T11:20:08.420852",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.383514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genome_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genome_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(df_train,df_movies,on = 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011896,
     "end_time": "2021-06-14T11:20:08.480518",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.468622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EDA\n",
    "Discovery phase and data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average rating\n",
    "a=dataset\n",
    "a=a.groupby('title')['rating'].mean().head()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the rating of each movie\n",
    "b=dataset.groupby('title')['rating'].count()\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a new dataframe\n",
    "new_record = pd.DataFrame()\n",
    "new_record['Average_ratings']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_record['Count of total ratings'] = b\n",
    "new_record.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of num of \n",
    "plt.figure(figsize=(10,9))\n",
    "\n",
    "new_record['Count of total ratings'].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of ratings column\n",
    "plt.figure(figsize =(10,4))\n",
    "\n",
    "new_record['Average_ratings'].hist(bins = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.jointplot(x='Average_ratings',  y='Count of total ratings',data=new_record,alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df=pd.merge(df_train, df_movies,on='movieId',how='inner')\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genres with highest rating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_count=movies_df['genres'].value_counts().sort_values(ascending=False)\n",
    "genre_count=pd.DataFrame(genre_count)\n",
    "top_genre=genre_count[0:11]\n",
    "top_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the number of times a user rated a movie\n",
    "user_df = pd.DataFrame(\n",
    "    df_train['userId'].value_counts()).reset_index()\n",
    "user_df.rename(columns={'index':'userId','userId':'count'},\n",
    "                  inplace=True)\n",
    "user_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "data = df_train['userId'].value_counts().head(10)\n",
    "ax = sns.barplot(x = data.index, y = data, order= data.index, palette='CMRmap', edgecolor=\"black\")\n",
    "plt.title(f'Top 10 Users by Number of Ratings', fontsize=14)\n",
    "plt.xlabel('User ID')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that user the with id **72315** has the highest rating count of **12952**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRating_Group = df_train['rating'].value_counts().sort_index().reset_index()\n",
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "sns.barplot(data=movieRating_Group, x='index', y='rating', palette=\"CMRmap\", edgecolor=\"black\", ax=ax)\n",
    "ax.set_xlabel(\"Rating\")\n",
    "ax.set_ylabel('Number of Users')\n",
    "ax.set_yticklabels(['{:,}'.format(int(x)) for x in ax.get_yticks().tolist()])\n",
    "total = float(movieRating_Group['rating'].sum())\n",
    "plt.title('Number of Users Per Rating', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011758,
     "end_time": "2021-06-14T11:20:08.504322",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.492564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Most common Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.255771,
     "end_time": "2021-06-14T11:20:08.772264",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.516493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dataframe containing only the movieId and genres\n",
    "movies_genres = pd.DataFrame(df_movies[['movieId', 'genres']],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\n",
    "movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n",
    "\n",
    "# Create expanded dataframe where each movie-genre combination is in a seperate row\n",
    "movies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "movies_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "papermill": {
     "duration": 0.347466,
     "end_time": "2021-06-14T11:20:09.132573",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.785107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the genres from most common to least common\n",
    "plot = plt.figure(figsize=(15, 10))\n",
    "plt.title('Most common genres\\n', fontsize=20)\n",
    "sns.countplot(y=\"genres\", data=movies_genres,\n",
    "              order=movies_genres['genres'].value_counts(ascending=False).index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for title in movies_df['title']:\n",
    "    if title[-1] == \" \":\n",
    "        year = title[-6: -2]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "    else:\n",
    "        year = title[-5: -1]\n",
    "        try:\n",
    "            dates.append(int(year))\n",
    "        except:\n",
    "            dates.append(9999)\n",
    "\n",
    "movies_df['Year'] = dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Years in which movies were released**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(y=\"Year\", data=movies_df, palette=\"Set2\", order=movies_df['Year'].value_counts().index[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, **1995** was the year when most of the movies were released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('title')['rating'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame(dataset.groupby('title')['rating'].mean())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['num of ratings'] = pd.DataFrame(dataset.groupby('title')['rating'].count())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "ratings['num of ratings'].hist(bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "ratings['rating'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='rating',y='num of ratings',data=ratings,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for title in df_movies['title']:\n",
    "    yearpub_subset = title[-5:-1]\n",
    "    try: years.append(int(yearpub_subset))\n",
    "    except: years.append(9999)\n",
    "        \n",
    "df_movies['yearpub'] = years\n",
    "print(len(df_movies[df_movies['yearpub'] == 9999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_histogram(dataset, attribute, bins=25, bar_color='#3498db', edge_color='#2980b9', title='Title', xlab='X', ylab='Y', sort_index=False):\n",
    "    if attribute == 'yearpub':\n",
    "        dataset = dataset[dataset['yearpub'] != 9999]\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(title, fontsize=24, pad=20)\n",
    "    ax.set_xlabel(xlab, fontsize=16, labelpad=20)\n",
    "    ax.set_ylabel(ylab, fontsize=16, labelpad=20)\n",
    "    \n",
    "    plt.hist(dataset[attribute], bins=bins, color=bar_color, ec=edge_color, linewidth=2)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    \n",
    "make_histogram(df_movies, 'yearpub', title='Movies per year distribution', xlab='year', ylab='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.DataFrame()\n",
    "ratings_df['Mean_Rating'] = dataset.groupby('title')['rating'].mean().values\n",
    "ratings_df['Num_Ratings'] = dataset.groupby('title')['rating'].count().values\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_title('Rating vs. Number of Ratings', fontsize=24, pad=20)\n",
    "ax.set_xlabel('Rating', fontsize=16, labelpad=20)\n",
    "ax.set_ylabel('Number of Ratings', fontsize=16, labelpad=20)\n",
    "\n",
    "plt.scatter(ratings_df['Mean_Rating'], ratings_df['Num_Ratings'], alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012939,
     "end_time": "2021-06-14T11:20:09.159029",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.14609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T15:11:56.868263Z",
     "iopub.status.busy": "2021-07-05T15:11:56.867939Z",
     "iopub.status.idle": "2021-07-05T15:11:56.974830Z",
     "shell.execute_reply": "2021-07-05T15:11:56.973863Z",
     "shell.execute_reply.started": "2021-07-05T15:11:56.868234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    2652977\n",
       "3.0    1959759\n",
       "5.0    1445230\n",
       "3.5    1270642\n",
       "4.5     880516\n",
       "2.0     656821\n",
       "2.5     505578\n",
       "1.0     311213\n",
       "1.5     159731\n",
       "0.5     157571\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5163</td>\n",
       "      <td>57669</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1518349992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106343</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1206238739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146790</td>\n",
       "      <td>5459</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1076215539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106362</td>\n",
       "      <td>32296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1423042565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9041</td>\n",
       "      <td>366</td>\n",
       "      <td>3.0</td>\n",
       "      <td>833375837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0    5163    57669     4.0  1518349992\n",
       "1  106343        5     4.5  1206238739\n",
       "2  146790     5459     5.0  1076215539\n",
       "3  106362    32296     2.0  1423042565\n",
       "4    9041      366     3.0   833375837"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T15:21:29.538595Z",
     "iopub.status.busy": "2021-07-05T15:21:29.538265Z",
     "iopub.status.idle": "2021-07-05T15:21:31.736164Z",
     "shell.execute_reply": "2021-07-05T15:21:31.735149Z",
     "shell.execute_reply.started": "2021-07-05T15:21:29.538563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "users = df_train.sample(n = 10000000, replace = False)\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(users[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Evaluating RMSE of algorithm SVD on 4 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Mean    Std     \n",
      "RMSE (testset)    0.8519  0.8519  0.8521  0.8529  0.8522  0.0004  \n",
      "Fit time          335.92  361.24  344.33  396.22  359.43  23.12   \n",
      "Test time         32.16   32.69   34.47   32.94   33.07   0.86    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.85187862, 0.85192456, 0.8520577 , 0.85285586]),\n",
       " 'fit_time': (335.9232130050659,\n",
       "  361.2407441139221,\n",
       "  344.3270184993744,\n",
       "  396.21927762031555),\n",
       " 'test_time': (32.16224217414856,\n",
       "  32.692840337753296,\n",
       "  34.473952531814575,\n",
       "  32.94402766227722)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(verbose=True, n_epochs=12)\n",
    "cross_validate(svd, data, measures=['RMSE'], cv=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013848,
     "end_time": "2021-06-14T11:20:09.278819",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.264971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate your outputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013303,
     "end_time": "2021-06-14T11:20:09.305786",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.292483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prepare Submission File\n",
    "We make submissions in CSV files. Your submissions usually have two columns: an ID column and a prediction column. The ID field comes from the test data (keeping whatever name the ID field had in that data, which for the data is the string 'Id'). The prediction column will use the name of the target field.\n",
    "\n",
    "We will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "papermill": {
     "duration": 0.019235,
     "end_time": "2021-06-14T11:20:09.338682",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.319447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_svd_hyper = [svd.predict(row.userId,\n",
    "                                         row.movieId) for idx,row in df_test.iterrows()]\n",
    "\n",
    "# Converting the predictions to a dataframe\n",
    "test_pred_svd_hyper = pd.DataFrame(pred_svd_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013706,
     "end_time": "2021-06-14T11:20:09.365804",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.352098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Make Submission\n",
    "Hit the blue Publish button at the top of your notebook screen. It will take some time for your kernel to run. When it has finished your navigation bar at the top of the screen will have a tab for Output. This only shows up if you have written an output file (like we did in the Prepare Submission File step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01348,
     "end_time": "2021-06-14T11:20:09.393074",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.379594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Example below of how the output would look once published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "papermill": {
     "duration": 0.026311,
     "end_time": "2021-06-14T11:20:09.433177",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.406866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.633416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4144</td>\n",
       "      <td>4.159102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5767</td>\n",
       "      <td>3.567240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6711</td>\n",
       "      <td>3.770057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7318</td>\n",
       "      <td>3.072327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId    rating\n",
       "0       1     2011  3.633416\n",
       "1       1     4144  4.159102\n",
       "2       1     5767  3.567240\n",
       "3       1     6711  3.770057\n",
       "4       1     7318  3.072327"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the fields in the prediction dataframe\n",
    "test_pred_svd_hyper.drop(['r_ui', 'details'], axis=1, inplace=True)\n",
    "test_pred_svd_hyper = test_pred_svd_hyper.rename(columns={'uid':'userId',\n",
    "                                                          'iid':'movieId',\n",
    "                                                          'est':'rating'})\n",
    "test_pred_svd_hyper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "papermill": {
     "duration": 0.023908,
     "end_time": "2021-06-14T11:20:09.470967",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.447059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate each userId and movieId into a single Id column for submission\n",
    "test_pred_svd_hyper['Id'] =  test_pred_svd_hyper['userId'].astype(str).str.zfill(1) + '_' + test_pred_svd_hyper['movieId'].astype(str).str.zfill(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_2011</td>\n",
       "      <td>3.633416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_4144</td>\n",
       "      <td>4.159102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_5767</td>\n",
       "      <td>3.567240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_6711</td>\n",
       "      <td>3.770057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_7318</td>\n",
       "      <td>3.072327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id    rating\n",
       "0  1_2011  3.633416\n",
       "1  1_4144  4.159102\n",
       "2  1_5767  3.567240\n",
       "3  1_6711  3.770057\n",
       "4  1_7318  3.072327"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_hyper_predictions = test_pred_svd_hyper[['Id','rating']]\n",
    "svd_hyper_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "papermill": {
     "duration": 0.013439,
     "end_time": "2021-06-14T11:20:09.498408",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.484969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_hyper_predictions.to_csv('submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
